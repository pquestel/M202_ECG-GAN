{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15640,"status":"ok","timestamp":1669922625492,"user":{"displayName":"CENNET TUGCE TURAN","userId":"11607656021567769031"},"user_tz":480},"id":"diSvxk9x2yhK","outputId":"d853022a-2010-4500-fa0d-1c60c30f283a"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.9.2\n"]}],"source":["# !pip install -q tensorflow-gpu==2.0.0-beta0\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers, regularizers\n","#from torch_two_sample.statistics_diff import MMDStatistic\n","import torch\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","import scipy.io\n","\n","from IPython import display\n","from tqdm import tqdm\n","from shutil import copyfile\n","\n","\n","print(tf.__version__)\n","\n","\n","# from google.colab import drive\n","# drive.mount('/drive')\n","\n","\n","norm_value = 1 #2173\n","\n","\n","#################################################################################\n","#          Helper functions\n","#################################################################################\n","def test_show(generator, discriminator):\n","    noise = tf.random.normal([1, 125, 50])\n","    generated_ecg = generator(noise, training=False)\n","    print(generated_ecg.shape)\n","    plt.plot(generated_ecg[0, 0, :])\n","    plt.show()\n","    \n","    decision = discriminator(generated_ecg, training=False)\n","    print(decision)\n","    \n","\n","def generate_and_save_ecg(model, epoch, test_input, save):\n","    predictions = model(test_input, training=False)\n","\n","    fig = plt.figure(figsize=(4,3))\n","    plt.plot(predictions[0, 0, :] * norm_value)\n","    # plt.plot(predictions[0, 0, :])\n","    \n","    if save:\n","        plt.savefig('./ecg_at_epoch_{:04d}.png'.format(epoch))\n","\n","    plt.show()\n","    \n","\n","def prepare_data(dim):\n","#     copyfile(f\"/drive/My Drive/Colab Notebooks/data/fix_signals_400.npy\", \"./fix_signals.npy\")\n","\n","    #Changes Philippe\n","    mat = scipy.io.loadmat(r\"/content/sample_data/interp_data_norm.mat\")\n","    \n","    data = mat['interp_data'] \n","    data = np.reshape(data, (data.shape[0],1,data.shape[1]))\n","\n","\n","    #data = np.load('./data/fix_signals_400.npy')\n","    #data = np.reshape(data, (data.shape[0], 1, data.shape[1]))\n","    print('Data shape:', data.shape)\n","\n","\n","    data = data #/ norm_value # Normalize\n","    data = np.array(data, dtype='float32')\n","    data = data[:576]\n","    print(data.shape)\n","    print(np.amax(data))\n","    print(np.amin(data))\n","\n","    plt.figure(figsize=(4,3))\n","    plt.plot(data[random.randint(0, data.shape[0]-1)][0])\n","    plt.show()\n","\n","    train_size = int(data.shape[0] * 0.9)\n","    test_size = data.shape[0] - train_size\n","    print(train_size, test_size)\n","\n","    # Batch and shuffle the data\n","    train_dataset = tf.data.Dataset.from_tensor_slices(data[:train_size]).shuffle(train_size).batch(BATCH_SIZE)\n","    test_dataset  = tf.data.Dataset.from_tensor_slices(data[train_size:]).shuffle(test_size).batch(1)\n","\n","    seed = tf.random.normal(dim)\n","    \n","    return seed, train_dataset, test_dataset"]},{"cell_type":"markdown","metadata":{"id":"TorJM8KFcGls"},"source":["# New Section"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2397,"status":"ok","timestamp":1669922627884,"user":{"displayName":"CENNET TUGCE TURAN","userId":"11607656021567769031"},"user_tz":480},"id":"1Yrhlemc9GIv","outputId":"cf77235d-4a1e-4c82-8ef2-2264a6d66d7f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," bidirectional (Bidirectiona  (None, 100, 128)         39424     \n"," l)                                                              \n","                                                                 \n"," conv1d (Conv1D)             (None, 100, 128)          262272    \n","                                                                 \n"," leaky_re_lu (LeakyReLU)     (None, 100, 128)          0         \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 100, 64)           131136    \n","                                                                 \n"," leaky_re_lu_1 (LeakyReLU)   (None, 100, 64)           0         \n","                                                                 \n"," up_sampling1d (UpSampling1D  (None, 200, 64)          0         \n"," )                                                               \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 200, 32)           32800     \n","                                                                 \n"," leaky_re_lu_2 (LeakyReLU)   (None, 200, 32)           0         \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 200, 16)           8208      \n","                                                                 \n"," leaky_re_lu_3 (LeakyReLU)   (None, 200, 16)           0         \n","                                                                 \n"," up_sampling1d_1 (UpSampling  (None, 400, 16)          0         \n"," 1D)                                                             \n","                                                                 \n"," conv1d_4 (Conv1D)           (None, 400, 1)            257       \n","                                                                 \n"," permute (Permute)           (None, 1, 400)            0         \n","                                                                 \n","=================================================================\n","Total params: 474,097\n","Trainable params: 474,097\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," permute_1 (Permute)         (None, 400, 1)            0         \n","                                                                 \n"," conv1d_5 (Conv1D)           (None, 400, 32)           544       \n","                                                                 \n"," leaky_re_lu_4 (LeakyReLU)   (None, 400, 32)           0         \n","                                                                 \n"," conv1d_6 (Conv1D)           (None, 400, 64)           32832     \n","                                                                 \n"," leaky_re_lu_5 (LeakyReLU)   (None, 400, 64)           0         \n","                                                                 \n"," max_pooling1d (MaxPooling1D  (None, 200, 64)          0         \n"," )                                                               \n","                                                                 \n"," conv1d_7 (Conv1D)           (None, 200, 128)          131200    \n","                                                                 \n"," leaky_re_lu_6 (LeakyReLU)   (None, 200, 128)          0         \n","                                                                 \n"," conv1d_8 (Conv1D)           (None, 200, 256)          524544    \n","                                                                 \n"," leaky_re_lu_7 (LeakyReLU)   (None, 200, 256)          0         \n","                                                                 \n"," max_pooling1d_1 (MaxPooling  (None, 100, 256)         0         \n"," 1D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 25600)             0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 25601     \n","                                                                 \n","=================================================================\n","Total params: 714,721\n","Trainable params: 714,721\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["def make_generator_model():\n","    model = tf.keras.Sequential()\n","    model.add(layers.Input(shape=(100, 12)))\n","\n","    model.add(layers.Bidirectional(layers.LSTM(64, return_sequences=True)))\n","\n","    model.add(layers.Conv1D(filters=128, kernel_size=16, strides=1, padding='same'))\n","    model.add(layers.LeakyReLU())\n","  \n","    model.add(layers.Conv1D(filters=64, kernel_size=16, strides=1, padding='same'))\n","    model.add(layers.LeakyReLU())\n","    \n","    model.add(layers.UpSampling1D(2))\n","    \n","    model.add(layers.Conv1D(filters=32, kernel_size=16, strides=1, padding='same'))\n","    model.add(layers.LeakyReLU())\n","    \n","    model.add(layers.Conv1D(filters=16, kernel_size=16, strides=1, padding='same'))\n","    model.add(layers.LeakyReLU())\n","\n","    model.add(layers.UpSampling1D(2))\n","    \n","    model.add(layers.Conv1D(filters=1, kernel_size=16, strides=1, padding='same', activation='tanh'))\n","    \n","    model.add(layers.Permute((2, 1)))\n","    \n","    return model\n","\n","\n","def make_discriminator_model():\n","    model = tf.keras.Sequential()\n","   \n","    model.add(layers.Input(shape=(1, 400)))\n","    model.add(layers.Permute((2, 1)))\n","    \n","    model.add(layers.Conv1D(filters=32, kernel_size=16, strides=1, padding='same'))\n","    model.add(layers.LeakyReLU())\n","\n","    # model.add(layers.Dropout(0.4))\n","\n","    model.add(layers.Conv1D(filters=64, kernel_size=16, strides=1, padding='same'))\n","    model.add(layers.LeakyReLU())\n","\n","    model.add(layers.MaxPool1D(pool_size=2))\n","\n","    model.add(layers.Conv1D(filters=128, kernel_size=16, strides=1, padding='same'))\n","    model.add(layers.LeakyReLU())\n","\n","    # model.add(layers.Dropout(0.4))\n","\n","    model.add(layers.Conv1D(filters=256, kernel_size=16, strides=1, padding='same'))\n","    model.add(layers.LeakyReLU())\n","\n","    model.add(layers.MaxPool1D(pool_size=2))\n","\n","    model.add(layers.Flatten())\n","    model.add(layers.Dense(1))\n","\n","    return model\n","\n","generator     = make_generator_model()\n","discriminator = make_discriminator_model()\n","    \n","generator.summary()\n","discriminator.summary()\n","\n","# test_show(generator, discriminator)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":318,"status":"ok","timestamp":1669922628198,"user":{"displayName":"CENNET TUGCE TURAN","userId":"11607656021567769031"},"user_tz":480},"id":"ULoCBqer9V_H"},"outputs":[],"source":["#################################################################################\n","#          Prepare metrics for logging\n","#################################################################################\n","\n","# !rm -rf ./logs/\n","\n","### discriminator loss ###\n","disc_log_dir = 'logs/gradient_tape/disc_loss'\n","disc_summary_writer = tf.summary.create_file_writer(disc_log_dir)\n","disc_losses = tf.keras.metrics.Mean('disc_loss', dtype=tf.float32)\n","disc_losses_list = []\n","\n","### discriminator accuracy ###\n","fake_disc_accuracy = tf.keras.metrics.BinaryAccuracy('fake_disc_accuracy')\n","real_disc_accuracy = tf.keras.metrics.BinaryAccuracy('real_disc_accuracy')\n","fake_disc_accuracy_list, real_disc_accuracy_list = [], []\n","\n","### generator loss ###\n","gen_log_dir = 'logs/gradient_tape/gen_loss'\n","gen_summary_writer = tf.summary.create_file_writer(gen_log_dir)\n","gen_losses = tf.keras.metrics.Mean('gen_loss', dtype=tf.float32)\n","gen_losses_list = []\n","\n","\n","#################################################################################\n","#          Prepare loss functions and optimizers\n","#################################################################################\n","\n","# This method returns a helper function to compute cross entropy loss\n","cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","\n","def discriminator_loss(real_output, fake_output):\n","    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n","    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n","    total_loss = real_loss + fake_loss\n","    return total_loss\n","\n","def generator_loss(fake_output):\n","    return cross_entropy(tf.ones_like(fake_output), fake_output)\n","\n","generator_optimizer = tf.keras.optimizers.Adam(0.0002)\n","discriminator_optimizer = tf.keras.optimizers.Adam(0.0002)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1669922628198,"user":{"displayName":"CENNET TUGCE TURAN","userId":"11607656021567769031"},"user_tz":480},"id":"7u2iNppZ9sku"},"outputs":[],"source":["disc_steps = 1\n","\n","# Notice the use of `tf.function`\n","# This annotation causes the function to be \"compiled\".\n","\n","@tf.function\n","def train_step(real_ecg, dim):\n","    noise = tf.random.normal(dim)\n","\n","    for i in range(disc_steps):\n","        with tf.GradientTape() as disc_tape:\n","            generated_ecg = generator(noise, training=True)\n","\n","            real_output = discriminator(real_ecg, training=True)\n","            fake_output = discriminator(generated_ecg, training=True)\n","\n","            disc_loss = discriminator_loss(real_output, fake_output)\n","        \n","        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n","        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n","        \n","        ### for tensorboard ###\n","        disc_losses.update_state(disc_loss)\n","        fake_disc_accuracy.update_state(tf.zeros_like(fake_output), fake_output)\n","        real_disc_accuracy.update_state(tf.ones_like(real_output), real_output)\n","        #######################\n","    \n","    with tf.GradientTape() as gen_tape:\n","        generated_ecg = generator(noise, training=True)\n","        fake_output = discriminator(generated_ecg, training=True)\n","\n","        gen_loss = generator_loss(fake_output)\n","    \n","    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n","    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n","\n","    ### for tensorboard ###\n","    gen_losses.update_state(gen_loss)\n","    #######################\n","    \n","\n","def train(dataset, epochs, dim):\n","    for epoch in tqdm(range(epochs)):\n","    \n","        for batch in dataset:\n","            train_step(batch, dim)\n","            \n","        disc_losses_list.append(disc_losses.result().numpy())\n","        gen_losses_list.append(gen_losses.result().numpy())\n","        \n","        fake_disc_accuracy_list.append(fake_disc_accuracy.result().numpy())\n","        real_disc_accuracy_list.append(real_disc_accuracy.result().numpy())\n","        \n","        ## for tensorboard ###\n","        with disc_summary_writer.as_default():\n","            tf.summary.scalar('loss', disc_losses.result(), step=epoch)\n","            tf.summary.scalar('fake_accuracy', fake_disc_accuracy.result(), step=epoch)\n","            tf.summary.scalar('real_accuracy', real_disc_accuracy.result(), step=epoch)\n","            \n","        with gen_summary_writer.as_default():\n","            tf.summary.scalar('loss', gen_losses.result(), step=epoch)\n","            \n","        disc_losses.reset_states()        \n","        gen_losses.reset_states()\n","        \n","        fake_disc_accuracy.reset_states()\n","        real_disc_accuracy.reset_states()\n","        #######################\n","        generate_and_save_ecg(generator, epochs, seed, False)\n","        # Save the model every 5 epochs\n","#         if (epoch + 1) % 5 == 0:\n","#             generate_and_save_ecg(generator, epochs, seed, False)\n","#             checkpoint.save(file_prefix = checkpoint_prefix)\n","\n","    # Generate after the final epoch\n","    display.clear_output(wait=True)\n","    generate_and_save_ecg(generator, epochs, seed, False)\n","    \n","#     generator.save('/content/drive/My Drive/Colab Notebooks/saved_models/generator_1500.h5')\n","#     discriminator.save('/content/drive/My Drive/Colab Notebooks/saved_models/discriminator_1500.h5')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":452},"executionInfo":{"elapsed":665,"status":"error","timestamp":1669922628862,"user":{"displayName":"CENNET TUGCE TURAN","userId":"11607656021567769031"},"user_tz":480},"id":"w3o7ZlWOK1Hg","outputId":"84ea0d36-41e6-4b8c-d611-467c2a7db253"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/sample_data/interp_data_norm.mat'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-43a296d7da36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnoise_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-2-417066c3d489>\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(dim)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m#Changes Philippe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"/content/sample_data/interp_data_norm.mat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'interp_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \"\"\"\n\u001b[1;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise IOError(\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/sample_data/interp_data_norm.mat'"]}],"source":["BATCH_SIZE = 64\n","noise_dim = [BATCH_SIZE, 100, 12]\n","\n","seed, train_dataset, test_dataset = prepare_data(noise_dim)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yx8xSU1v929d","executionInfo":{"status":"aborted","timestamp":1669922628863,"user_tz":480,"elapsed":6,"user":{"displayName":"CENNET TUGCE TURAN","userId":"11607656021567769031"}}},"outputs":[],"source":["train(train_dataset, 5, noise_dim)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1669922628864,"user":{"displayName":"CENNET TUGCE TURAN","userId":"11607656021567769031"},"user_tz":480},"id":"mt08T3oUvue7"},"outputs":[],"source":["# %reload_ext tensorboard\n","# %tensorboard --logdir logs/gradient_tape\n","\n","fig, axes = plt.subplots(2, figsize=(12, 8))\n","fig.suptitle('Training Metrics')\n","\n","axes[0].set_ylabel(\"Losses\", fontsize=14)\n","axes[0].set_xlabel(\"Epoch\", fontsize=14)\n","axes[0].plot(disc_losses_list, color='red')\n","axes[0].plot(gen_losses_list, color='blue')\n","\n","axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n","axes[1].set_xlabel(\"Epoch\", fontsize=14)\n","axes[1].plot(fake_disc_accuracy_list, color='red')\n","axes[1].plot(real_disc_accuracy_list, color='blue')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1669922628864,"user":{"displayName":"CENNET TUGCE TURAN","userId":"11607656021567769031"},"user_tz":480},"id":"Mk_e-Ke8Fbm_"},"outputs":[],"source":["seed = tf.random.normal(noise_dim)\n","ecg = generator(seed, training=False)\n","answer = discriminator(ecg)\n","fig = plt.figure(figsize=(4,3))\n","plt.plot(ecg[0, 0, :] * norm_value)\n","plt.show()\n","print(answer[0])"]},{"cell_type":"code","source":["# Convert Keras model to a tflite model\n","converter = tf.lite.TFLiteConverter.from_keras_model(generator)\n","#converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n","tflite_model = converter.convert()\n","\n","open(tflite_model +'.tflite', 'wb').write(tflite_model)"],"metadata":{"id":"LvMu9TkMo6gy","executionInfo":{"status":"aborted","timestamp":1669922628865,"user_tz":480,"elapsed":7,"user":{"displayName":"CENNET TUGCE TURAN","userId":"11607656021567769031"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1669922628865,"user":{"displayName":"CENNET TUGCE TURAN","userId":"11607656021567769031"},"user_tz":480},"id":"K-xX3W_-dwN0"},"outputs":[],"source":["generator.save('/drive/My Drive/Colab Notebooks/saved_models/generator_80e.h5')\n","discriminator.save('/drive/My Drive/Colab Notebooks/saved_models/discriminator_80e.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1669922628866,"user":{"displayName":"CENNET TUGCE TURAN","userId":"11607656021567769031"},"user_tz":480},"id":"3E3dDE7JMvm2"},"outputs":[],"source":["model = tf.keras.models.load_model('generator_80e.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1669922628866,"user":{"displayName":"CENNET TUGCE TURAN","userId":"11607656021567769031"},"user_tz":480},"id":"4ASzOhS9R5on"},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1669922628866,"user":{"displayName":"CENNET TUGCE TURAN","userId":"11607656021567769031"},"user_tz":480},"id":"5aIoDPI5SI5-"},"outputs":[],"source":["seed = tf.random.normal([1, 100, 12])\n","ecg = model(seed, training=False)\n","fig = plt.figure(figsize=(4,3))\n","plt.plot(ecg[0, 0, :] * norm_value)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y-UNv4JABqTR","executionInfo":{"status":"aborted","timestamp":1669922628866,"user_tz":480,"elapsed":7,"user":{"displayName":"CENNET TUGCE TURAN","userId":"11607656021567769031"}}},"outputs":[],"source":["#################################################################################\n","#          Testing functions\n","#################################################################################\n","def rmse(targets, predictions):\n","    return np.sqrt(np.mean((targets-predictions)**2))\n","\n","\n","def prd(targets, predictions):\n","    s1 = np.sum((targets-predictions)**2)\n","    s2 = np.sum(targets**2)\n","    return np.sqrt(s1 / s2 * 100)\n","\n","\n","def mmd(targets, predictions):\n","    mmd_stat = MMDStatistic(400, 400)\n","    sample_target = torch.from_numpy(targets.numpy().reshape((400,1)))\n","    sample_pred = torch.from_numpy(predictions.numpy().reshape((400,1)))\n","    \n","    stat = mmd_stat(sample_target, sample_pred, [1.])\n","    return(stat.item())\n","\n","\n","def testing(test_dataset, model, noise_dim):\n","    noise = tf.random.normal(noise_dim)\n","    generated_ecgs = model(noise, training=False)\n","\n","    mmd_sum, prd_sum, rmse_sum = [], [], []\n","    for true_ecg, gen_ecg in zip(test_dataset, generated_ecgs):\n","        prd_sum.append(prd(true_ecg[0][0], gen_ecg[0]))\n","        rmse_sum.append(rmse(true_ecg[0][0], gen_ecg[0]))\n","        mmd_sum.append(mmd(true_ecg[0][0], gen_ecg[0]))\n","\n","    print('mmd :', f'mean={np.mean(mmd_sum):.6f}', f'min={np.min(mmd_sum):.6f}', f'max={np.max(mmd_sum):.6f}')\n","    print('prd :', f'mean={np.mean(prd_sum):.4f}', f'min={np.min(prd_sum):.4f}', f'max={np.max(prd_sum):.4f}')\n","    print('rmse:', f'mean={np.mean(rmse_sum):.4f}', f'min={np.min(rmse_sum):.4f}', f'max={np.max(rmse_sum):.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1669922628867,"user":{"displayName":"CENNET TUGCE TURAN","userId":"11607656021567769031"},"user_tz":480},"id":"rm9jiDCyaQYP"},"outputs":[],"source":["testing(test_dataset, model, [763, 100, 12])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m6HwS7tGPKFQ","executionInfo":{"status":"aborted","timestamp":1669922628867,"user_tz":480,"elapsed":8,"user":{"displayName":"CENNET TUGCE TURAN","userId":"11607656021567769031"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/MikhailMurashov/ecgGAN/blob/master/ecgGAN.ipynb","timestamp":1667759910743}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}