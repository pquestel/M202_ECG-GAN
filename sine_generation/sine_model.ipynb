{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMHDGQnS2rZsj05t7hyQ3xf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"0RcUmbU8rBn5","executionInfo":{"status":"ok","timestamp":1668206657303,"user_tz":480,"elapsed":567,"user":{"displayName":"CENNET TUGCE TURAN","userId":"11607656021567769031"}}},"outputs":[],"source":["\n","\"\"\"\n","Created on Tue Dec 24 20:25 2019\n","@author: anne marie delaney\n","         eoin brophy\n","         \n","Module of the GAN model for sine wave synthesis.\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"]},{"cell_type":"code","source":["\"\"\" \n","NN Definitions\n","---------------\n","Defining the Neural Network Classes to be evaluated in this Notebook\n","Minibatch Discrimination\n","--------------------------\n","Creating a module for Minibatch Discrimination to avoid mode collapse as described:\n","https://arxiv.org/pdf/1606.03498.pdf\n","https://torchgan.readthedocs.io/en/latest/modules/layers.html#minibatch-discrimination\n","\"\"\"\n","\n","class MinibatchDiscrimination(torch.nn.Module):\n","   def __init__(self,input_features,output_features,minibatch_normal_init, hidden_features=16):\n","      super(MinibatchDiscrimination,self).__init__()\n","      \n","      self.input_features = input_features\n","      self.output_features = output_features\n","      self.hidden_features = hidden_features\n","      self.T = torch.nn.Parameter(torch.randn(self.input_features,self.output_features, self.hidden_features))\n","      if minibatch_normal_init == True:\n","        nn.init.normal(self.T, 0,1)\n","      \n","   def forward(self,x):\n","      M = torch.mm(x,self.T.view(self.input_features,-1))\n","      M = M.view(-1, self.output_features, self.hidden_features).unsqueeze(0)\n","      M_t = M.permute(1, 0, 2, 3)\n","      # Broadcasting reduces the matrix subtraction to the form desired in the paper\n","      out = torch.sum(torch.exp(-(torch.abs(M - M_t).sum(3))), dim=0) - 1\n","      \n","      return torch.cat([x, out], 1)\n","    "],"metadata":{"id":"1gKcmspBrqJz","executionInfo":{"status":"ok","timestamp":1668206657304,"user_tz":480,"elapsed":4,"user":{"displayName":"CENNET TUGCE TURAN","userId":"11607656021567769031"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Discriminator Class\n","-------------------\n","This discriminator has a parameter num_cv which allows the user to specify if \n","they want to have 1 or 2 Convolution Neural Network Layers.\n","This discriminator has a parameter minibatch which allows the user to specify if \n","they want to include a MBD layer in the architecture. \n","minibatch = 0 means no MBD layer is included\n","minibatch >=1 means that there will be <minibatch> number of outputs from the MBD layer.\n","\"\"\"\n","\n","# Use minibatch = 0 for no minibatch discriminiation layer to be used in the architecture. If minibatch > 0, then minibatch is the number of output dimensions of the MBD layer.\n","class Discriminator(torch.nn.Module):\n","  def __init__(self,seq_length,batch_size,minibatch_normal_init, n_features = 1, num_cv = 1, minibatch = 0, cv1_out= 10, cv1_k = 3, cv1_s = 4, p1_k = 3, p1_s = 3, cv2_out = 10, cv2_k = 3, cv2_s = 3 ,p2_k = 3, p2_s = 3):\n","      super(Discriminator,self).__init__()\n","      self.n_features = n_features\n","      self.seq_length = seq_length\n","      self.batch_size = batch_size\n","      self.num_cv = num_cv\n","      self.minibatch = minibatch\n","      self.cv1_dims = int((((((seq_length - cv1_k)/cv1_s) + 1)-p1_k)/p1_s)+1)\n","      self.cv2_dims = int((((((self.cv1_dims - cv2_k)/cv2_s) + 1)-p2_k)/p2_s)+1)\n","      self.cv1_out = cv1_out\n","      self.cv2_out = cv2_out\n","      \n","      #input should be size (batch_size,num_features,seq_length) for the convolution layer\n","      self.CV1 = torch.nn.Sequential(\n","                  torch.nn.Conv1d(in_channels = self.n_features, out_channels = int(cv1_out),kernel_size = int(cv1_k), stride = int(cv1_s))\n","                  ,torch.nn.ReLU()        \n","                  ,torch.nn.MaxPool1d(kernel_size = int(p1_k), stride = int(p1_s))   \n","                 )\n","      \n","      # 2 convolutional layers\n","      if self.num_cv > 1:\n","        self.CV2 = torch.nn.Sequential(\n","                      torch.nn.Conv1d(in_channels = int(cv1_out), out_channels = int(cv2_out) ,kernel_size =int(cv2_k), stride = int(cv2_s))\n","                      ,torch.nn.ReLU()\n","                      ,torch.nn.MaxPool1d(kernel_size = int(p2_k), stride = int(p2_s))\n","                  )\n","        \n","        #Adding a minibatch discriminator layer to add a cripple affect to the discriminator so that it needs to generate sequences that are different from each other.\n","        \n","        if   self.minibatch > 0:\n","          self.mb1 = MinibatchDiscrimination(self.cv2_dims*cv2_out,self.minibatch, minibatch_normal_init)\n","          self.out = torch.nn.Sequential(torch.nn.Linear(int(self.cv2_dims*cv2_out)+self.minibatch,1),torch.nn.Sigmoid()) # to make sure the output is between 0 and 1\n","        else:\n","          self.out = torch.nn.Sequential(torch.nn.Linear(int(self.cv2_dims*cv2_out),1),torch.nn.Sigmoid()) # to make sure the output is between 0 and 1 \n","      \n","      # 1 convolutional layer\n","      else:\n","        #Adding a minibatch discriminator layer to add a cripple affect to the discriminator so that it needs to generate sequences that are different from each other.\n","        if self.minibatch > 0 :    \n","          self.mb1 = MinibatchDiscrimination(int(self.cv1_dims*cv1_out),self.minibatch, minibatch_normal_init)\n","          self.out = torch.nn.Sequential(torch.nn.Linear(int(self.cv1_dims*cv1_out)+self.minibatch,1),torch.nn.Dropout(0.2),torch.nn.Sigmoid()) # to make sure the output is between 0 and 1\n","        else:\n","          self.out = torch.nn.Sequential(torch.nn.Linear(int(self.cv1_dims*cv1_out),1),torch.nn.Sigmoid())  \n","\n","  def forward(self,x):\n","      x = self.CV1(x.view(self.batch_size,1,self.seq_length))\n","          \n","      #2 Convolutional Layers\n","      if self.num_cv > 1:   \n","        x = self.CV2(x)\n","        x = x.view(self.batch_size,-1)\n","        \n","        #2 CNN with minibatch discrimination\n","        if self.minibatch > 0:\n","             x = self.mb1(x.squeeze())\n","             x = self.out(x.squeeze())\n","             \n","        #2 CNN and no minibatch discrimination\n","        else:\n","             x = self.out(x.squeeze())\n","        \n","      # 1 Convolutional Layer\n","      else: \n","        x = x.view(self.batch_size,-1)\n","       \n","        #1 convolutional Layer and minibatch discrimination\n","        if self.minibatch > 0:\n","             x = self.mb1(x)\n","             x = self.out(x)\n","        \n","        #1 convolutional Layer and no minibatch discrimination\n","        else:\n","             x = self.out(x)\n","    \n","      return x\n","  "],"metadata":{"id":"CnnrmgrJ0d43","executionInfo":{"status":"ok","timestamp":1668206657304,"user_tz":480,"elapsed":4,"user":{"displayName":"CENNET TUGCE TURAN","userId":"11607656021567769031"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Generator Class\n","---------------\n","This defines the Generator for evaluation. The Generator consists of two LSTM \n","layers with a final fully connected layer.\n","This generator has a parameter called bidirectional which specifies if a LSTM \n","should be bidirectional or not.\n","\"\"\"\n","\n","class Generator(torch.nn.Module):\n","  \n","  def __init__(self,seq_length,batch_size,n_features = 1, hidden_dim = 50, num_layers = 2, tanh_output = False, bidirectional = False):\n","      super(Generator,self).__init__()\n","      self.n_features = n_features\n","      self.hidden_dim = hidden_dim\n","      self.num_layers = num_layers\n","      self.seq_length = seq_length\n","      self.batch_size = batch_size\n","      self.tanh_output = tanh_output\n","      self.bidirectional = bidirectional\n","      \n","      #Checking if the architecture uses a BiLSTM and setting the output parameters as appropriate.\n","      if self.bidirectional == True:\n","        self.num_dirs = 2\n","      else:\n","        self.num_dirs = 1\n","      \n","      \n","      self.layer1 = torch.nn.LSTM(input_size = self.n_features, hidden_size = self.hidden_dim, num_layers = self.num_layers,batch_first = True, bidirectional = self.bidirectional )\n","      self.out = torch.nn.Linear(self.hidden_dim,1) # to make sure the output is between 0 and 1 - removed ,torch.nn.Sigmoid()\n","      \n","      \n","  def init_hidden(self):\n","      weight = next(self.parameters()).data\n","      hidden = (weight.new(self.num_layers*self.num_dirs, self.batch_size, self.hidden_dim).zero_().cuda(),\n","                weight.new(self.num_layers*self.num_dirs, self.batch_size, self.hidden_dim).zero_().cuda())\n","      return hidden\n","  \n","  def forward(self,x,hidden):\n","      x,hidden = self.layer1(x.view(self.batch_size,self.seq_length,1),hidden)\n","      \n","      if self.bidirectional == True:\n","        x = x.view(x.size(0), x.size(1), 2, -1).sum(2).view(x.size(0), x.size(1), -1)\n","      \n","      #Note that the output of the bidirectional LSTM is in the form (batch_size,seq_lenth,num_dirs*hidden_dim) To separate the directions, we can use \n","      #x.view(self.batch_size,self.seq_length,self.num_dirs, self.hidden_dim)\n","      x = self.out(x)\n","      \n","      return x.squeeze() #,hidden \n","\n"],"metadata":{"id":"gpK8uAa9ypmn","executionInfo":{"status":"ok","timestamp":1668206657304,"user_tz":480,"elapsed":4,"user":{"displayName":"CENNET TUGCE TURAN","userId":"11607656021567769031"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Noise Definition\n","---------------\n","This defines the function for generating the randon noise required to train the GAN.\n","\"\"\"\n","def noise(batch_size, features):\n","  noise_vec = torch.randn(batch_size, features).cuda()\n","  return noise_vec"],"metadata":{"id":"qTIcPdAoy3cw","executionInfo":{"status":"ok","timestamp":1668206657304,"user_tz":480,"elapsed":3,"user":{"displayName":"CENNET TUGCE TURAN","userId":"11607656021567769031"}}},"execution_count":5,"outputs":[]}]}